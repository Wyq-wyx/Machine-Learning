{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* KNN的优点：精读高、对异常值不敏感、无数据输入假定\n",
    "* KNN的缺点：计算复杂度高、空间复杂度高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建数据集和标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset():\n",
    "    group = array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])\n",
    "    labels = ['A','A','B','B']\n",
    "    return group,labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify0(inX, dataSet, labels, k):\n",
    "    #距离计算\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    diffMat = tile(inX, (dataSetSize,1)) - dataSet  \n",
    "    sqDiffMat = diffMat ** 2\n",
    "    sqDistances = sqDiffMat.sum(axis = 1)\n",
    "    distances = sqDistances ** 0.5\n",
    "\n",
    "    sortedDistIndicies = distances.argsort()\n",
    "    classCount = {}\n",
    "    \n",
    "    #选择距离最小的k个点\n",
    "    for i in range(k):\n",
    "        voteIlabel = labels[sortedDistIndicies[i]]\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1\n",
    "\n",
    "    #排序\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sortedClassCount[0][0] #返回类别出现次数最多的分类名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tips"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tile(inX, (dataSetSize,1))：把输入向量沿第一个维度（这里相当于列）方向复制datasize倍，沿第二个维度（这里相当于行）方向复制1倍。\n",
    "eg：\n",
    "   A=['T']\n",
    "   print(\"0:\",A)\n",
    "   print(\"1:\",tile(A,2))\n",
    "   print(\"2:\",tile(A,(2,3)))\n",
    "   print(\"3:\",tile(A,(2,3,4)))\n",
    "output：\n",
    "   0: ['T']\n",
    "   1: ['T' 'T']\n",
    "   2: [['T' 'T' 'T']\n",
    "      ['T' 'T' 'T']]\n",
    "   3: [[['T' 'T' 'T' 'T']\n",
    "        ['T' 'T' 'T' 'T']\n",
    "        ['T' 'T' 'T' 'T']]\n",
    "\n",
    "       [['T' 'T' 'T' 'T']\n",
    "        ['T' 'T' 'T' 'T']\n",
    "        ['T' 'T' 'T' 'T']]]\n",
    "\n",
    "** ：幂运算\n",
    "\n",
    "sum:没有axis参数表示全部相加，axis＝0表示按列相加，axis＝1表示按照行的方向相加\n",
    "\n",
    "argsort():返回排序后的原来位置的索引\n",
    "eg:\n",
    "   V = [4,2,7,5]\n",
    "   print(argsort(V))\n",
    "output:\n",
    "   [1 0 3 2]\n",
    "\n",
    "sorted(classCount.items(), key=operator.itemgetter(1), reverse=True):按参数 key 排序，按字典的键的值降序排列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: B\n"
     ]
    }
   ],
   "source": [
    "group,labels = createDataset()\n",
    "print(\"result:\",classify0([0,0.2],group,labels,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.g.约会网站配对分类\n",
    "\n",
    "### 将文本记录转换为训练样本矩阵和类标签向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file2matrix(filename):\n",
    "    fr = open(filename)\n",
    "    arrayOLines = fr.readlines()\n",
    "    numberOfLines = len(arrayOLines) #得到文件行数\n",
    "    retrunMat = zeros((numberOfLines,3)) #创建训练样本矩阵\n",
    "    classKabekVedtor = [] #创建类标签向量\n",
    "    index = 0\n",
    "    for line in arrayOLines:\n",
    "        line = line.strip() #截取掉所有回车字符\n",
    "        listFromLine = line.split('\\t') #用\\t将上一步得到的整行数据分割成一个元素列表\n",
    "        retrunMat[index,:] = listFromLine[0:3] #取前3个元素存入矩阵中\n",
    "        classKabekVedtor.append(int(listFromLine[-1])) #负索引-1表示列表中最后一列元素\n",
    "        index += 1\n",
    "    return retrunMat,classKabekVedtor\n",
    "\n",
    "datingDataMat,datingLabels = file2matrix('datingTestSet2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用Matplotilb创建散点图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def showPlot():\n",
    "    type1_x = []; type1_y = []\n",
    "    type2_x = []; type2_y = []\n",
    "    type3_x = []; type3_y = []\n",
    "    for i in range(len(datingLabels)):\n",
    "        if datingLabels[i] == 1: #label=1\n",
    "            type1_x.append(datingDataMat[i][1])\n",
    "            type1_y.append(datingDataMat[i][2])\n",
    "        if datingLabels[i] == 2: #label=2\n",
    "            type2_x.append(datingDataMat[i][1])\n",
    "            type2_y.append(datingDataMat[i][2])\n",
    "        if datingLabels[i] == 3: #label=3\n",
    "            type3_x.append(datingDataMat[i][1])\n",
    "            type3_y.append(datingDataMat[i][2])\n",
    "    plt.figure()\n",
    "    plt.subplot(111)\n",
    "    type1 = plt.scatter(type1_x, type1_y, c = 'red', marker='.')\n",
    "    type2 = plt.scatter(type2_x, type2_y, c = 'green', marker='.')\n",
    "    type3 = plt.scatter(type3_x, type3_y, c = 'blue', marker='.')\n",
    "    plt.xlabel(\"ice-cream\")\n",
    "    plt.ylabel(\"video game\")\n",
    "    plt.legend((type1, type2, type3), (\"Didn't Like\", \"Small Doses\", \"Large Doses\"), loc = 0)\n",
    "    plt.show()\n",
    "\n",
    "showPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征值归一化\n",
    "newValue = (oldValue - min)/(max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoNorm(dataset):\n",
    "    minVals = dataset.min(0)\n",
    "    maxVals = dataset.max(0)\n",
    "    ranges = maxVals - minVals\n",
    "    normDataset = zeros(shape(dataset))\n",
    "    m = dataset.shape[0]\n",
    "    normDataset = dataset - tile(minVals,(m,1))\n",
    "    normDataset = normDataset / tile(ranges,(m,1))\n",
    "    return normDataset, ranges, minVals\n",
    "\n",
    "normMat, ranges, minVals = autoNorm(datingDataMat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the totla errror rate is: 0.050000\n"
     ]
    }
   ],
   "source": [
    "def datingClassTest():\n",
    "    testRatio = 0.1\n",
    "    # datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    # normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    m = normMat.shape[0]\n",
    "    numTestVecs = int(m * testRatio)\n",
    "    errorCount = 0\n",
    "    for i in range(numTestVecs):\n",
    "        classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)\n",
    "       # print(\"the classifier came back result: %d, the real answer is: %d\" % (classifierResult,datingLabels[i]))\n",
    "        if (classifierResult != datingLabels[i]):\n",
    "            errorCount += 1\n",
    "    print(\"the totla errror rate is: %f\" % (errorCount / float(numTestVecs)))\n",
    "\n",
    "datingClassTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "percentage of time spent playing video games: 30\n",
      "frequent flier miles earned per year: 1000\n",
      "liters of ice cream consumed per year: 1.1\n",
      "You will probably like this person: Large Does\n"
     ]
    }
   ],
   "source": [
    "def classifyPerson():\n",
    "    resultList = ['Didn\\'t Like', 'Small Does', 'Large Does']\n",
    "    percentTats = float(input(\"percentage of time spent playing video games: \"))\n",
    "    ffMiles = float(input(\"frequent flier miles earned per year: \"))\n",
    "    iceCream = float(input(\"liters of ice cream consumed per year: \"))\n",
    "    datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')\n",
    "    normedMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    inArr = array([ffMiles, percentTats, iceCream])\n",
    "    classifierResult = classify0((inArr - minVals) / ranges, normedMat, datingLabels, 3)\n",
    "    print(\"You will probably like this person:\", resultList[classifierResult - 1]) # classifyerResut-1:分类结果为123，而resultlist中排序是012\n",
    "\n",
    "classifyPerson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e.g.手写识别系统\n",
    "### 将图像转换为测试向量\n",
    "将32x32的图像转换为1x1024的向量：创建1x1024的数组，然后打开给定文件，循环读出文件的前32行，并将每行的头32个字符值存储在数组中，最后返回数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def img2vector(filename):\n",
    "    returnVect = zeros((1,1024))\n",
    "    fr = open(filename)\n",
    "    for i in range(32):\n",
    "        lineStr = fr.readline()\n",
    "        for j in range(32):\n",
    "            returnVect[0,32*i+j] = int(lineStr[j])\n",
    "    return returnVect\n",
    "\n",
    "# testvec = img2vector('digits/testDigits/0_13.txt')\n",
    "# print(testvec[0,0:31])\n",
    "# print(testvec[0,31:63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of errors is: 11\n",
      "the total error rate is: 0.011628\n"
     ]
    }
   ],
   "source": [
    "def handwritingClassTest():\n",
    "    hwLabels = []\n",
    "    trainingFileList = os.listdir('digits/trainingDigits') #获取目录\n",
    "    m = len(trainingFileList)\n",
    "    trainingMat = zeros((m,1024))\n",
    "    for i in range(m):\n",
    "        fileNameStr = trainingFileList[i] #读取每行数据文件名称\n",
    "        fileStr = fileNameStr.split('.')[0] #split文件，通过识别”.“,[0]代表除去后面的，即txt\n",
    "        classNumStr = int(fileStr.split('_')[0]) #split文件，通过识别”_”，[0]除去了0_3后面的序号3，保留0\n",
    "        hwLabels.append(classNumStr)\n",
    "        trainingMat[i,:] = img2vector('digits/trainingDigits/%s' % fileNameStr)\n",
    "    testFileList = os.listdir('digits/testDigits')\n",
    "    errorCount = 0\n",
    "    mTest = len(testFileList)\n",
    "    for i in range(mTest):\n",
    "        fileNameStr = testFileList[i]\n",
    "        fileStr = fileNameStr.split('.')[0]\n",
    "        classNumStr = int(fileStr.split('_')[0])\n",
    "        vectorUnderTest = img2vector('digits/testDigits/%s' % fileNameStr)\n",
    "        classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3)\n",
    "        # print(\"the classifier came back result with: %d, the real answer is: %d\" % (classifierResult, classNumStr))\n",
    "        if (classifierResult != classNumStr):\n",
    "            errorCount += 1\n",
    "    print(\"the total number of errors is: %d\" % errorCount)\n",
    "    print(\"the total error rate is: %f\" % (errorCount/float(mTest)))\n",
    "    \n",
    "handwritingClassTest()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
