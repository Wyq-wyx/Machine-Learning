{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR\n",
    "### 梯度上升算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "def loadDataset():\n",
    "    dataMat = []\n",
    "    labelMat = []\n",
    "    fr = open('testSet.txt')\n",
    "    for line in fr.readlines():\n",
    "        lineArr = line.strip().split()\n",
    "        dataMat.append([1.0,float(lineArr[0]),float(lineArr[1])])\n",
    "        labelMat.append(int(lineArr[2]))\n",
    "    return dataMat, labelMat\n",
    "\n",
    "def sigmoid(inX):\n",
    "    if inX.any() >= 0:\n",
    "        return 1.0 / (1 + exp(-inX))\n",
    "    else:\n",
    "        return exp(inX) / (1 + exp(inX))\n",
    "    \n",
    "def gradAscent(dataMatIn, classLabels):\n",
    "    dataMatrix = mat(dataMatIn)\n",
    "    labelMat = mat(classLabels).transpose()\n",
    "    m, n = shape(dataMatrix)\n",
    "    alpha = 0.001  #目标移动的步长\n",
    "    maxCycles = 500  #迭代次数\n",
    "    weights = ones((n,1))\n",
    "    for k in range(maxCycles):\n",
    "        h = sigmoid(dataMatrix * weights)\n",
    "        error = (labelMat - h)\n",
    "        weights = weights + alpha * dataMatrix.transpose() * error\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析数据：画出决策边界"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBestFit(weights):\n",
    "    import matplotlib.pyplot as plt\n",
    "    # weights = wei.getA()  #getA()将weights矩阵转换为数组\n",
    "    dataMat, labelMat = loadDataset()\n",
    "    dataArr = array(dataMat)\n",
    "    n = shape(dataArr)[0]\n",
    "    xcord1 = []\n",
    "    ycord1 = []\n",
    "    xcord2 = []\n",
    "    ycord2 = []\n",
    "    for i in range(n):\n",
    "        if int(labelMat[i] == 1):\n",
    "            xcord1.append(dataArr[i,1])\n",
    "            ycord1.append(dataArr[i,2])\n",
    "        else:\n",
    "            xcord2.append(dataArr[i, 1])\n",
    "            ycord2.append(dataArr[i, 2])\n",
    "    plt.figure()\n",
    "    plt.subplot(111)\n",
    "    plt.scatter(xcord1,ycord1,s=30,c='red',marker='s')\n",
    "    plt.scatter(xcord2,ycord2,s=30,c='green')\n",
    "    x = arange(-3.0, 3.0, 0.1)\n",
    "    y = (-weights[0]-weights[1]*x) / weights[2]\n",
    "    plt.plot(x,y)\n",
    "    plt.xlabel('X1')\n",
    "    plt.ylabel('X2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 随机梯度上升算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocGradAscent0(dataMatrix, classLabels):\n",
    "    m,n = shape(dataMatrix)\n",
    "    alpha = 0.01\n",
    "    weights = ones(n)\n",
    "    for i in range(m):\n",
    "        h = sigmoid(sum(dataMatrix[i]*weights))\n",
    "        error = classLabels[i] - h\n",
    "        weights = weights + alpha * error * dataMatrix[i]\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对回归系数进行更新的公式为：w：w+alpha*gradient,其中gradient是对参数w求偏导数\n",
    "推导：https://www.cnblogs.com/zy230530/p/6875145.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进后的随机梯度上升算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stocGradAscent1(dataMatrix, classLabels, numIter = 500):\n",
    "    m, n = shape(dataMatrix)\n",
    "    weights = ones(n)\n",
    "    for j in range(numIter):\n",
    "        dataIndex = range(m)\n",
    "        for i in range(m):\n",
    "            alpha = 4/(1.0+j+i)+0.01  #alpha每次迭代时需要调整\n",
    "            randIndex = int(random.uniform(0,len(dataIndex)))  #随机选取更新\n",
    "            h = sigmoid(sum(dataMatrix[randIndex] * weights))\n",
    "            error = classLabels[randIndex] - h\n",
    "            weights = weights + alpha * error * dataMatrix[randIndex]\n",
    "            del(list(dataIndex)[randIndex])\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测病马死亡率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyVector(inX, weights):\n",
    "    prob = sigmoid(sum(inX * weights))\n",
    "    if prob > 0.5:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 0.0\n",
    "def colicTest():\n",
    "    frTrain = open('horseColicTraining.txt')\n",
    "    frTest = open('horseColicTest.txt')\n",
    "    trainingSet = []\n",
    "    trainingLabels = []\n",
    "    for line in frTrain.readlines():\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        trainingSet.append(lineArr)\n",
    "        trainingLabels.append(float(currLine[21]))\n",
    "    trainWeights = stocGradAscent1(array(trainingSet),trainingLabels)\n",
    "    errorCount = 0\n",
    "    numTestVec = 0.0\n",
    "    for line in frTest.readlines():\n",
    "        numTestVec += 1.0\n",
    "        currLine = line.strip().split('\\t')\n",
    "        lineArr = []\n",
    "        for i in range(21):\n",
    "            lineArr.append(float(currLine[i]))\n",
    "        if classifyVector(array(lineArr),trainWeights) != int(currLine[21]):\n",
    "            errorCount += 1\n",
    "    errorRate = (float(errorCount)/numTestVec)\n",
    "    print(\"the error rate of this test is: %f\" % errorRate)\n",
    "    return errorRate\n",
    "\n",
    "def multiTest():\n",
    "    numTests = 10\n",
    "    errorSum = 0.0\n",
    "    for k in range(numTests):\n",
    "        errorSum += colicTest()\n",
    "    print(\"after %d iterations the average error rate is: %f\" % (numTests, errorSum/float(numTests)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the error rate of this test is: 0.268657\n",
      "the error rate of this test is: 0.298507\n",
      "the error rate of this test is: 0.253731\n",
      "the error rate of this test is: 0.373134\n",
      "the error rate of this test is: 0.328358\n",
      "the error rate of this test is: 0.238806\n",
      "the error rate of this test is: 0.328358\n",
      "the error rate of this test is: 0.298507\n",
      "the error rate of this test is: 0.283582\n",
      "the error rate of this test is: 0.298507\n",
      "after 10 iterations the average error rate is: 0.297015\n"
     ]
    }
   ],
   "source": [
    "multiTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
